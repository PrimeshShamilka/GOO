{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "from models.gazenet import GazeNet\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from utils import data_transforms\n",
    "from utils import get_paste_kernel, kernel_map\n",
    "import pickle\n",
    "\n",
    "class GazeDataset(Dataset):\n",
    "    def __init__(self, root_dir, mat_file, training='train', include_path=False):\n",
    "        assert (training in set(['train', 'test']))\n",
    "        self.root_dir = root_dir\n",
    "        self.mat_file = mat_file\n",
    "        self.training = training\n",
    "        self.include_path = include_path\n",
    "\n",
    "        anns = loadmat(self.mat_file)\n",
    "        self.bboxes = anns[self.training + '_bbox'] #Literally not used for anything lol\n",
    "        self.gazes = anns[self.training + '_gaze']\n",
    "        self.paths = anns[self.training + '_path']\n",
    "        self.eyes = anns[self.training + '_eyes']\n",
    "        self.meta = anns[self.training + '_meta']\n",
    "        self.image_num = self.paths.shape[0]\n",
    "        \n",
    "        print(self.bboxes[0,0][0])\n",
    "        print(self.gazes[0,0][0])\n",
    "        #print(len(self.paths))\n",
    "        print(self.eyes[0,0][0])\n",
    "\n",
    "        logging.info('%s contains %d images' % (self.mat_file, self.image_num))\n",
    "\n",
    "    def generate_data_field(self, eye_point):\n",
    "        \"\"\"eye_point is (x, y) and between 0 and 1\"\"\"\n",
    "        height, width = 224, 224\n",
    "        x_grid = np.array(range(width)).reshape([1, width]).repeat(height, axis=0)\n",
    "        y_grid = np.array(range(height)).reshape([height, 1]).repeat(width, axis=1)\n",
    "        grid = np.stack((x_grid, y_grid)).astype(np.float32)\n",
    "\n",
    "        x, y = eye_point\n",
    "        x, y = x * width, y * height\n",
    "\n",
    "        grid -= np.array([x, y]).reshape([2, 1, 1]).astype(np.float32)\n",
    "        norm = np.sqrt(np.sum(grid ** 2, axis=0)).reshape([1, height, width])\n",
    "        # avoid zero norm\n",
    "        norm = np.maximum(norm, 0.1)\n",
    "        grid /= norm\n",
    "        return grid\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.paths[idx][0][0]\n",
    "        image_path = os.path.join(self.root_dir, image_path)\n",
    "\n",
    "        box = self.bboxes[0, idx][0]\n",
    "        eye = self.eyes[0, idx][0]\n",
    "        # todo: process gaze differently for training or testing\n",
    "        gaze = self.gazes[0, idx].mean(axis=0)\n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if random.random() > 0.5 and self.training == 'train':\n",
    "            eye = [1.0 - eye[0], eye[1]]\n",
    "            gaze = [1.0 - gaze[0], gaze[1]]\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "        # crop face\n",
    "        x_c, y_c = eye\n",
    "        x_0 = x_c - 0.15\n",
    "        y_0 = y_c - 0.15\n",
    "        x_1 = x_c + 0.15\n",
    "        y_1 = y_c + 0.15\n",
    "        if x_0 < 0:\n",
    "            x_0 = 0\n",
    "        if y_0 < 0:\n",
    "            y_0 = 0\n",
    "        if x_1 > 1:\n",
    "            x_1 = 1\n",
    "        if y_1 > 1:\n",
    "            y_1 = 1\n",
    "        h, w = image.shape[:2]\n",
    "        face_image = image[int(y_0 * h):int(y_1 * h), int(x_0 * w):int(x_1 * w), :]\n",
    "        # process face_image for face net\n",
    "        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "        face_image = Image.fromarray(face_image)\n",
    "        face_image = data_transforms[self.training](face_image)\n",
    "        # process image for saliency net\n",
    "        #image = image_preprocess(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        image = data_transforms[self.training](image)\n",
    "\n",
    "        # generate gaze field\n",
    "        gaze_field = self.generate_data_field(eye_point=eye)\n",
    "        # generate heatmap\n",
    "        heatmap = get_paste_kernel((224 // 4, 224 // 4), gaze, kernel_map, (224 // 4, 224 // 4))\n",
    "        '''\n",
    "        direction = gaze - eye\n",
    "        norm = (direction[0] ** 2.0 + direction[1] ** 2.0) ** 0.5\n",
    "        if norm <= 0.0:\n",
    "            norm = 1.0\n",
    "\n",
    "        direction = direction / norm\n",
    "        '''\n",
    "        \n",
    "        if self.include_path:\n",
    "            sample = {'image' : image,\n",
    "                      'face_image': face_image,\n",
    "                      'eye_position': torch.FloatTensor(eye),\n",
    "                      'gaze_field': torch.from_numpy(gaze_field),\n",
    "                      'gt_position': torch.FloatTensor(gaze),\n",
    "                      'gt_heatmap': torch.FloatTensor(heatmap).unsqueeze(0),\n",
    "                      'image_path': image_path}\n",
    "        else:\n",
    "            sample = {'image' : image,\n",
    "                  'face_image': face_image,\n",
    "                  'eye_position': torch.FloatTensor(eye),\n",
    "                  'gaze_field': torch.from_numpy(gaze_field),\n",
    "                  'gt_position': torch.FloatTensor(gaze),\n",
    "                  'gt_heatmap': torch.FloatTensor(heatmap).unsqueeze(0)\n",
    "                     }\n",
    "\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GooDataset(Dataset):\n",
    "    def __init__(self, root_dir, mat_file, training='train',include_path=False):\n",
    "        assert (training in set(['train', 'test']))\n",
    "        self.root_dir = root_dir\n",
    "        self.mat_file = mat_file\n",
    "        self.training = training\n",
    "        self.include_path = include_path\n",
    "\n",
    "        with open(mat_file, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "            self.image_num = len(self.data)\n",
    "            \n",
    "        print(self.image_num)\n",
    "        logging.info('%s contains %d images' % (self.mat_file, self.image_num))\n",
    "\n",
    "    def generate_data_field(self, eye_point):\n",
    "        \"\"\"eye_point is (x, y) and between 0 and 1\"\"\"\n",
    "        height, width = 224, 224\n",
    "        x_grid = np.array(range(width)).reshape([1, width]).repeat(height, axis=0)\n",
    "        y_grid = np.array(range(height)).reshape([height, 1]).repeat(width, axis=1)\n",
    "        grid = np.stack((x_grid, y_grid)).astype(np.float32)\n",
    "\n",
    "        x, y = eye_point\n",
    "        x, y = x * width, y * height\n",
    "\n",
    "        grid -= np.array([x, y]).reshape([2, 1, 1]).astype(np.float32)\n",
    "        norm = np.sqrt(np.sum(grid ** 2, axis=0)).reshape([1, height, width])\n",
    "        # avoid zero norm\n",
    "        norm = np.maximum(norm, 0.1)\n",
    "        grid /= norm\n",
    "        return grid\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "                     \n",
    "        data = self.data[idx]\n",
    "        image_path = data['filename']\n",
    "        image_path = os.path.join(self.root_dir, image_path)\n",
    "        #print(image_path)\n",
    "        \n",
    "        eye = [float(data['hx'])/640, float(data['hy'])/480]\n",
    "        gaze = [float(data['gaze_cx'])/640, float(data['gaze_cy'])/480]\n",
    "        #print('eye coords: ', eye)\n",
    "        #print('gaze coords: ', gaze)\n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if random.random() > 0.5 and self.training == 'train':\n",
    "            eye = [1.0 - eye[0], eye[1]]\n",
    "            gaze = [1.0 - gaze[0], gaze[1]]\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "        # crop face\n",
    "        x_c, y_c = eye\n",
    "        x_0 = x_c - 0.15\n",
    "        y_0 = y_c - 0.15\n",
    "        x_1 = x_c + 0.15\n",
    "        y_1 = y_c + 0.15\n",
    "        if x_0 < 0:\n",
    "            x_0 = 0\n",
    "        if y_0 < 0:\n",
    "            y_0 = 0\n",
    "        if x_1 > 1:\n",
    "            x_1 = 1\n",
    "        if y_1 > 1:\n",
    "            y_1 = 1\n",
    "        h, w = image.shape[:2]\n",
    "        face_image = image[int(y_0 * h):int(y_1 * h), int(x_0 * w):int(x_1 * w), :]\n",
    "        # process face_image for face net\n",
    "        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "        face_image = Image.fromarray(face_image)\n",
    "        face_image = data_transforms[self.training](face_image)\n",
    "        # process image for saliency net\n",
    "        #image = image_preprocess(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        image = data_transforms[self.training](image)\n",
    "\n",
    "        # generate gaze field\n",
    "        gaze_field = self.generate_data_field(eye_point=eye)\n",
    "        # generate heatmap\n",
    "        heatmap = get_paste_kernel((224 // 4, 224 // 4), gaze, kernel_map, (224 // 4, 224 // 4))\n",
    "        '''\n",
    "        direction = gaze - eye\n",
    "        norm = (direction[0] ** 2.0 + direction[1] ** 2.0) ** 0.5\n",
    "        if norm <= 0.0:\n",
    "            norm = 1.0\n",
    "\n",
    "        direction = direction / norm\n",
    "        '''\n",
    "        \n",
    "        if self.include_path:\n",
    "            sample = {'image' : image,\n",
    "                      'face_image': face_image,\n",
    "                      'eye_position': torch.FloatTensor(eye),\n",
    "                      'gaze_field': torch.from_numpy(gaze_field),\n",
    "                      'gt_position': torch.FloatTensor(gaze),\n",
    "                      'gt_heatmap': torch.FloatTensor(heatmap).unsqueeze(0),\n",
    "                      'image_path': image_path}\n",
    "        else:\n",
    "            sample = {'image' : image,\n",
    "                  'face_image': face_image,\n",
    "                  'eye_position': torch.FloatTensor(eye),\n",
    "                  'gaze_field': torch.from_numpy(gaze_field),\n",
    "                  'gt_position': torch.FloatTensor(gaze),\n",
    "                  'gt_heatmap': torch.FloatTensor(heatmap).unsqueeze(0)\n",
    "                     }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29 0.11 0.68 0.89]\n",
      "[0.51090909 0.31132813]\n",
      "[0.41272727 0.21429687]\n",
      "[0.09 0.52 0.27 0.48]\n",
      "[0.284 0.86 ]\n",
      "[0.258      0.60666667]\n"
     ]
    }
   ],
   "source": [
    "#For gazefollow\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_set = GazeDataset(root_dir='/home/eee198/Documents/datasets/GazeFollowData/',\n",
    "                        mat_file='/home/eee198/Documents/datasets/GazeFollowData/train_annotations.mat',\n",
    "                        training='train')\n",
    "train_data_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                               shuffle=True, num_workers=16)\n",
    "\n",
    "test_set = GazeDataset(root_dir='/home/eee198/Documents/datasets/GazeFollowData/',\n",
    "                       mat_file='/home/eee198/Documents/datasets/GazeFollowData/test_annotations.mat',\n",
    "                       training='test', include_path=True)\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                              shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200\n"
     ]
    }
   ],
   "source": [
    "#For GOO\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "test_set = GooDataset(root_dir='/hdd/HENRI/goosynth/test/',\n",
    "                       mat_file='/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle',\n",
    "                       training='test', include_path=True)\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                              shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye coords: eye coords: eye coords: eye coords:     [0.3484375, 0.5020833333333333][0.1921875, 0.4][0.5390625, 0.5479166666666667][0.3765625, 0.29791666666666666]eye coords: \n",
      "eye coords:  \n",
      "eye coords: \n",
      "\n",
      "[0.7640625, 0.38333333333333336]gaze coords: gaze coords: gaze coords: "
     ]
    }
   ],
   "source": [
    "sample = next(iter(test_data_loader))\n",
    "print(sample.keys())\n",
    "\n",
    "#Image check\n",
    "print(len(sample['image_path']))\n",
    "print(sample['image_path'][0])\n",
    "print(sample['eye_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
