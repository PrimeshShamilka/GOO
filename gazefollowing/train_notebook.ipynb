{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "from scipy import signal\n",
    "\n",
    "from utils import data_transforms\n",
    "from utils import get_paste_kernel, kernel_map\n",
    "from utils_logging import setup_logger\n",
    "\n",
    "from models.gazenet import GazeNet\n",
    "from dataloading import GazeDataset\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from training.train_gazenet import train, test\n",
    "from training.train_gazenet import StagedOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logger(name='first_logger', \n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='train.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger.info(\"Log test if working again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GazeNet(\n",
       "    (face_net): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "    (face_process): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "    )\n",
       "    (fpn_net): FPN(\n",
       "      (relu): ReLU(inplace)\n",
       "      (resnet): ResNet(\n",
       "        (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "        (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "      )\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (c5_conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (c4_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (c3_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (c2_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p5_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p4_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p2_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (sigmoid): Sigmoid()\n",
       "      (predict): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (eye_position_transform): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "    )\n",
       "    (fusion): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main\n",
    "    \n",
    "batch_size = 32\n",
    "\n",
    "train_set = GazeDataset(root_dir='/home/eee198/Documents/datasets/GazeFollowData/',\n",
    "                        mat_file='/home/eee198/Documents/datasets/GazeFollowData/train_annotations.mat',\n",
    "                        training='train')\n",
    "train_data_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                               shuffle=True, num_workers=16)\n",
    "\n",
    "test_set = GazeDataset(root_dir='/home/eee198/Documents/datasets/GazeFollowData/',\n",
    "                       mat_file='/home/eee198/Documents/datasets/GazeFollowData/test_annotations.mat',\n",
    "                       training='test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                              shuffle=False, num_workers=8)\n",
    "\n",
    "net = GazeNet()\n",
    "net = DataParallel(net)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/299 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/temp/model_epoch25.pth.tar'\n",
      "=>Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/temp/model_epoch25.pth.tar' (epoch 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/Documents/gaze-on-objects/gazefollowing/training/train_gazenet.py:110: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  map(lambda x: Variable(x.cuda(), volatile=True), [image, face_image, gaze_field, eye_position, gt_position, gt_heatmap])\n",
      "loss: 0.06168, 0.11927, 0.18096\n",
      "  0%|          | 1/299 [00:01<07:16,  1.46s/it]loss: 0.05558, 0.11232, 0.16790\n",
      "  1%|          | 2/299 [00:01<05:17,  1.07s/it]loss: 0.06302, 0.11029, 0.17331\n",
      "  1%|          | 3/299 [00:01<03:56,  1.25it/s]loss: 0.06081, 0.08591, 0.14672\n",
      "  1%|▏         | 4/299 [00:01<02:55,  1.69it/s]loss: 0.05679, 0.03788, 0.09466\n",
      "  2%|▏         | 5/299 [00:02<02:13,  2.20it/s]loss: 0.05022, 0.08001, 0.13022\n",
      "loss: 0.06150, 0.17127, 0.23277\n",
      "  2%|▏         | 7/299 [00:02<01:41,  2.89it/s]loss: 0.05873, 0.06466, 0.12339\n",
      "  3%|▎         | 8/299 [00:02<01:22,  3.51it/s]loss: 0.05862, 0.08342, 0.14204\n",
      "  3%|▎         | 9/299 [00:02<01:08,  4.20it/s]loss: 0.05867, 0.03987, 0.09854\n",
      "  3%|▎         | 10/299 [00:02<00:59,  4.82it/s]loss: 0.05301, 0.19217, 0.24518\n",
      "  4%|▎         | 11/299 [00:02<00:50,  5.69it/s]loss: 0.05280, 0.05494, 0.10774\n",
      "  4%|▍         | 12/299 [00:02<00:44,  6.42it/s]loss: 0.05110, 0.04898, 0.10008\n",
      "  4%|▍         | 13/299 [00:02<00:42,  6.79it/s]loss: 0.05815, 0.15145, 0.20960\n",
      "  5%|▍         | 14/299 [00:03<00:40,  7.02it/s]loss: 0.05223, 0.05644, 0.10867\n",
      "loss: 0.06078, 0.09972, 0.16049\n",
      "  5%|▌         | 16/299 [00:03<00:39,  7.25it/s]loss: 0.05484, 0.05454, 0.10938\n",
      "  6%|▌         | 17/299 [00:03<00:37,  7.55it/s]loss: 0.06157, 0.04784, 0.10941\n",
      "loss: 0.05582, 0.04253, 0.09835\n",
      "  6%|▋         | 19/299 [00:03<00:33,  8.36it/s]loss: 0.06546, 0.12248, 0.18795\n",
      "  7%|▋         | 20/299 [00:03<00:33,  8.40it/s]loss: 0.06851, 0.20088, 0.26939\n",
      "  7%|▋         | 21/299 [00:03<00:35,  7.80it/s]loss: 0.05103, 0.02960, 0.08062\n",
      "  7%|▋         | 22/299 [00:04<00:36,  7.61it/s]loss: 0.07210, 0.24617, 0.31827\n",
      "  8%|▊         | 23/299 [00:04<00:35,  7.81it/s]loss: 0.05895, 0.12261, 0.18156\n",
      "  8%|▊         | 24/299 [00:04<00:34,  7.90it/s]loss: 0.05126, 0.09271, 0.14397\n",
      "  8%|▊         | 25/299 [00:04<00:34,  7.84it/s]loss: 0.06331, 0.06323, 0.12655\n",
      "  9%|▊         | 26/299 [00:04<00:34,  7.89it/s]loss: 0.05504, 0.03366, 0.08870\n",
      "  9%|▉         | 27/299 [00:04<00:34,  7.88it/s]loss: 0.05882, 0.07318, 0.13199\n",
      "  9%|▉         | 28/299 [00:04<00:33,  7.98it/s]loss: 0.05441, 0.05825, 0.11266\n",
      " 10%|▉         | 29/299 [00:04<00:32,  8.23it/s]loss: 0.06007, 0.05176, 0.11183\n",
      " 10%|█         | 30/299 [00:05<00:31,  8.64it/s]loss: 0.06286, 0.09939, 0.16224\n",
      " 10%|█         | 31/299 [00:05<00:30,  8.65it/s]loss: 0.04881, 0.05232, 0.10113\n",
      " 11%|█         | 32/299 [00:05<00:32,  8.29it/s]loss: 0.06166, 0.25922, 0.32088\n",
      " 11%|█         | 33/299 [00:05<00:33,  8.01it/s]loss: 0.04986, 0.02177, 0.07163\n",
      " 11%|█▏        | 34/299 [00:05<00:34,  7.76it/s]loss: 0.06592, 0.08258, 0.14850\n",
      " 12%|█▏        | 35/299 [00:05<00:31,  8.32it/s]loss: 0.06283, 0.19940, 0.26223\n",
      " 12%|█▏        | 36/299 [00:05<00:34,  7.63it/s]loss: 0.05200, 0.05373, 0.10573\n",
      " 12%|█▏        | 37/299 [00:05<00:39,  6.64it/s]loss: 0.05443, 0.04663, 0.10107\n",
      "loss: 0.05910, 0.09928, 0.15837\n",
      " 13%|█▎        | 39/299 [00:06<00:34,  7.49it/s]loss: 0.05567, 0.03284, 0.08851\n",
      " 13%|█▎        | 40/299 [00:06<00:32,  8.01it/s]loss: 0.06144, 0.13863, 0.20007\n",
      "loss: 0.05962, 0.04646, 0.10608\n",
      " 14%|█▍        | 42/299 [00:06<00:30,  8.52it/s]loss: 0.05874, 0.14397, 0.20271\n",
      " 14%|█▍        | 43/299 [00:06<00:29,  8.60it/s]loss: 0.05313, 0.06760, 0.12072\n",
      "loss: 0.06314, 0.21691, 0.28004\n",
      " 15%|█▌        | 45/299 [00:06<00:28,  8.88it/s]loss: 0.05957, 0.06473, 0.12429\n",
      " 15%|█▌        | 46/299 [00:06<00:30,  8.29it/s]loss: 0.06049, 0.21954, 0.28003\n",
      " 16%|█▌        | 47/299 [00:07<00:34,  7.32it/s]loss: 0.04995, 0.05546, 0.10541\n",
      " 16%|█▌        | 48/299 [00:07<00:32,  7.72it/s]loss: 0.07593, 0.29701, 0.37295\n",
      " 16%|█▋        | 49/299 [00:07<00:31,  7.85it/s]loss: 0.06678, 0.14812, 0.21490\n",
      "loss: 0.06174, 0.11540, 0.17713\n",
      " 17%|█▋        | 51/299 [00:07<00:29,  8.31it/s]loss: 0.06620, 0.15422, 0.22042\n",
      " 17%|█▋        | 52/299 [00:07<00:29,  8.29it/s]loss: 0.05340, 0.09497, 0.14838\n",
      " 18%|█▊        | 53/299 [00:07<00:29,  8.41it/s]loss: 0.05262, 0.05561, 0.10823\n",
      " 18%|█▊        | 54/299 [00:07<00:29,  8.27it/s]loss: 0.06415, 0.13699, 0.20114\n",
      " 18%|█▊        | 55/299 [00:08<00:28,  8.64it/s]loss: 0.05404, 0.07295, 0.12699\n",
      " 19%|█▊        | 56/299 [00:08<00:27,  8.75it/s]loss: 0.06380, 0.09720, 0.16101\n",
      " 19%|█▉        | 57/299 [00:08<00:28,  8.57it/s]loss: 0.06622, 0.18588, 0.25210\n",
      " 19%|█▉        | 58/299 [00:08<00:28,  8.34it/s]loss: 0.06226, 0.27247, 0.33474\n",
      " 20%|█▉        | 59/299 [00:08<00:28,  8.50it/s]loss: 0.05425, 0.14615, 0.20040\n",
      "loss: 0.06257, 0.04604, 0.10861\n",
      " 20%|██        | 61/299 [00:08<00:27,  8.81it/s]loss: 0.05176, 0.07191, 0.12367\n",
      " 21%|██        | 62/299 [00:08<00:26,  8.92it/s]loss: 0.06115, 0.09139, 0.15254\n",
      "loss: 0.05736, 0.10964, 0.16699\n",
      " 21%|██▏       | 64/299 [00:08<00:24,  9.41it/s]loss: 0.06814, 0.13503, 0.20317\n",
      " 22%|██▏       | 65/299 [00:09<00:25,  9.35it/s]loss: 0.06756, 0.15359, 0.22115\n",
      " 22%|██▏       | 66/299 [00:09<00:26,  8.72it/s]loss: 0.05257, 0.17953, 0.23210\n",
      " 22%|██▏       | 67/299 [00:09<00:26,  8.70it/s]loss: 0.05386, 0.02126, 0.07512\n",
      "loss: 0.06522, 0.12773, 0.19295\n",
      " 23%|██▎       | 69/299 [00:09<00:24,  9.40it/s]loss: 0.06401, 0.14786, 0.21187\n",
      " 23%|██▎       | 70/299 [00:09<00:24,  9.25it/s]loss: 0.05956, 0.12688, 0.18644\n",
      "loss: 0.06508, 0.09443, 0.15951\n",
      " 24%|██▍       | 72/299 [00:09<00:25,  9.03it/s]loss: 0.06672, 0.17539, 0.24211\n",
      " 24%|██▍       | 73/299 [00:09<00:24,  9.26it/s]loss: 0.06145, 0.17164, 0.23310\n",
      " 25%|██▍       | 74/299 [00:10<00:25,  8.83it/s]loss: 0.05826, 0.18219, 0.24045\n",
      " 25%|██▌       | 75/299 [00:10<00:30,  7.33it/s]loss: 0.05275, 0.03834, 0.09109\n",
      " 25%|██▌       | 76/299 [00:10<00:30,  7.39it/s]loss: 0.05213, 0.07154, 0.12367\n",
      "loss: 0.05411, 0.04932, 0.10343\n",
      " 26%|██▌       | 78/299 [00:10<00:26,  8.25it/s]loss: 0.06540, 0.06113, 0.12653\n",
      "loss: 0.05682, 0.02661, 0.08343\n",
      " 27%|██▋       | 80/299 [00:10<00:25,  8.68it/s]loss: 0.05702, 0.09067, 0.14769\n",
      " 27%|██▋       | 81/299 [00:10<00:27,  7.93it/s]loss: 0.05701, 0.08510, 0.14211\n",
      " 27%|██▋       | 82/299 [00:11<00:28,  7.53it/s]loss: 0.06488, 0.15190, 0.21678\n",
      " 28%|██▊       | 83/299 [00:11<00:27,  7.80it/s]loss: 0.05745, 0.04525, 0.10270\n",
      " 28%|██▊       | 84/299 [00:11<00:29,  7.29it/s]loss: 0.06516, 0.25594, 0.32110\n",
      " 28%|██▊       | 85/299 [00:11<00:30,  6.96it/s]loss: 0.06550, 0.10077, 0.16628\n",
      "loss: 0.05223, 0.08496, 0.13718\n",
      " 29%|██▉       | 87/299 [00:11<00:27,  7.79it/s]loss: 0.05259, 0.05030, 0.10289\n",
      " 29%|██▉       | 88/299 [00:11<00:25,  8.30it/s]loss: 0.05758, 0.12231, 0.17989\n",
      "loss: 0.06803, 0.16235, 0.23038\n",
      " 30%|███       | 90/299 [00:11<00:23,  9.08it/s]loss: 0.05100, 0.17429, 0.22529\n",
      " 30%|███       | 91/299 [00:12<00:23,  8.72it/s]loss: 0.04943, 0.04315, 0.09258\n",
      " 31%|███       | 92/299 [00:12<00:23,  8.66it/s]loss: 0.06894, 0.23156, 0.30049\n",
      " 31%|███       | 93/299 [00:12<00:25,  8.21it/s]loss: 0.05134, 0.06051, 0.11185\n",
      " 31%|███▏      | 94/299 [00:12<00:23,  8.55it/s]loss: 0.05416, 0.07377, 0.12794\n",
      " 32%|███▏      | 95/299 [00:12<00:25,  7.97it/s]loss: 0.07378, 0.21197, 0.28575\n",
      " 32%|███▏      | 96/299 [00:12<00:25,  7.82it/s]loss: 0.06052, 0.39516, 0.45569\n",
      " 32%|███▏      | 97/299 [00:12<00:24,  8.18it/s]loss: 0.06170, 0.03663, 0.09833\n",
      " 33%|███▎      | 98/299 [00:12<00:24,  8.04it/s]loss: 0.06384, 0.10286, 0.16670\n",
      "loss: 0.06949, 0.10958, 0.17907\n",
      " 33%|███▎      | 100/299 [00:13<00:22,  8.78it/s]loss: 0.06416, 0.15088, 0.21504\n",
      "loss: 0.06916, 0.41511, 0.48426\n",
      " 34%|███▍      | 102/299 [00:13<00:21,  9.21it/s]loss: 0.06878, 0.23929, 0.30807\n",
      " 34%|███▍      | 103/299 [00:13<00:21,  9.22it/s]loss: 0.05844, 0.09152, 0.14996\n",
      " 35%|███▍      | 104/299 [00:13<00:21,  9.00it/s]loss: 0.05833, 0.13482, 0.19315\n",
      " 35%|███▌      | 105/299 [00:13<00:22,  8.47it/s]loss: 0.05531, 0.17370, 0.22901\n",
      "loss: 0.04853, 0.03268, 0.08120\n",
      " 36%|███▌      | 107/299 [00:13<00:21,  8.95it/s]loss: 0.06156, 0.10787, 0.16943\n",
      " 36%|███▌      | 108/299 [00:14<00:20,  9.15it/s]loss: 0.05679, 0.13426, 0.19105\n",
      "loss: 0.05473, 0.04670, 0.10142\n",
      " 37%|███▋      | 110/299 [00:14<00:19,  9.66it/s]loss: 0.06597, 0.25673, 0.32270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.05783, 0.05266, 0.11049\n",
      " 37%|███▋      | 112/299 [00:14<00:18, 10.25it/s]loss: 0.06575, 0.09278, 0.15853\n",
      "loss: 0.05508, 0.10581, 0.16089\n",
      " 38%|███▊      | 114/299 [00:14<00:19,  9.73it/s]loss: 0.06422, 0.15661, 0.22083\n",
      "loss: 0.05597, 0.06377, 0.11974\n",
      " 39%|███▉      | 116/299 [00:14<00:19,  9.57it/s]loss: 0.05769, 0.17179, 0.22949\n",
      " 39%|███▉      | 117/299 [00:14<00:19,  9.19it/s]loss: 0.06515, 0.15367, 0.21883\n",
      " 39%|███▉      | 118/299 [00:15<00:20,  8.95it/s]loss: 0.07159, 0.08580, 0.15738\n",
      " 40%|███▉      | 119/299 [00:15<00:21,  8.54it/s]loss: 0.06403, 0.07940, 0.14343\n",
      "loss: 0.04949, 0.09425, 0.14375\n",
      " 40%|████      | 121/299 [00:15<00:19,  9.24it/s]loss: 0.06140, 0.06566, 0.12707\n",
      " 41%|████      | 122/299 [00:15<00:19,  8.92it/s]loss: 0.05325, 0.08707, 0.14032\n",
      " 41%|████      | 123/299 [00:15<00:19,  8.80it/s]loss: 0.05950, 0.14623, 0.20573\n",
      " 41%|████▏     | 124/299 [00:15<00:20,  8.53it/s]loss: 0.06310, 0.09676, 0.15986\n",
      " 42%|████▏     | 125/299 [00:15<00:19,  8.79it/s]loss: 0.06562, 0.46276, 0.52838\n",
      " 42%|████▏     | 126/299 [00:15<00:19,  9.06it/s]loss: 0.06497, 0.21407, 0.27904\n",
      " 42%|████▏     | 127/299 [00:16<00:19,  8.74it/s]loss: 0.05135, 0.03922, 0.09057\n",
      " 43%|████▎     | 128/299 [00:16<00:19,  8.56it/s]loss: 0.06249, 0.27815, 0.34065\n",
      "loss: 0.07080, 0.11541, 0.18622\n",
      " 43%|████▎     | 130/299 [00:16<00:18,  9.04it/s]loss: 0.05497, 0.11762, 0.17259\n",
      "loss: 0.05735, 0.08614, 0.14349\n",
      " 44%|████▍     | 132/299 [00:16<00:18,  8.88it/s]loss: 0.05828, 0.07232, 0.13060\n",
      " 44%|████▍     | 133/299 [00:16<00:18,  8.77it/s]loss: 0.06554, 0.03696, 0.10249\n",
      " 45%|████▍     | 134/299 [00:16<00:18,  9.04it/s]loss: 0.06338, 0.07614, 0.13952\n",
      "loss: 0.06775, 0.16105, 0.22879\n",
      " 45%|████▌     | 136/299 [00:17<00:17,  9.08it/s]loss: 0.06244, 0.07013, 0.13257\n",
      "loss: 0.05612, 0.06919, 0.12530\n",
      " 46%|████▌     | 138/299 [00:17<00:17,  9.45it/s]loss: 0.05884, 0.10115, 0.15999\n",
      " 46%|████▋     | 139/299 [00:17<00:17,  9.23it/s]loss: 0.06416, 0.18245, 0.24661\n",
      "loss: 0.06212, 0.05670, 0.11882\n",
      " 47%|████▋     | 141/299 [00:17<00:17,  9.25it/s]loss: 0.05895, 0.15843, 0.21738\n",
      "loss: 0.05059, 0.02143, 0.07202\n",
      " 48%|████▊     | 143/299 [00:17<00:16,  9.59it/s]loss: 0.06296, 0.12646, 0.18941\n",
      " 48%|████▊     | 144/299 [00:17<00:19,  7.90it/s]loss: 0.05865, 0.19906, 0.25771\n",
      "loss: 0.05357, 0.10062, 0.15420\n",
      " 49%|████▉     | 146/299 [00:18<00:18,  8.36it/s]loss: 0.05479, 0.11434, 0.16914\n",
      " 49%|████▉     | 147/299 [00:18<00:18,  8.05it/s]loss: 0.06035, 0.26116, 0.32150\n",
      " 49%|████▉     | 148/299 [00:18<00:18,  8.14it/s]loss: 0.05693, 0.17670, 0.23363\n",
      " 50%|████▉     | 149/299 [00:18<00:17,  8.52it/s]loss: 0.06000, 0.09269, 0.15269\n",
      " 50%|█████     | 150/299 [00:18<00:17,  8.74it/s]loss: 0.05251, 0.04925, 0.10175\n",
      " 51%|█████     | 151/299 [00:18<00:17,  8.70it/s]loss: 0.06266, 0.06568, 0.12834\n",
      " 51%|█████     | 152/299 [00:18<00:17,  8.29it/s]loss: 0.06304, 0.14634, 0.20939\n",
      " 51%|█████     | 153/299 [00:19<00:18,  7.83it/s]loss: 0.06774, 0.17154, 0.23929\n",
      " 52%|█████▏    | 154/299 [00:19<00:18,  7.89it/s]loss: 0.06372, 0.04128, 0.10500\n",
      " 52%|█████▏    | 155/299 [00:19<00:17,  8.26it/s]loss: 0.05973, 0.04312, 0.10285\n",
      "loss: 0.05558, 0.16575, 0.22133\n",
      " 53%|█████▎    | 157/299 [00:19<00:16,  8.87it/s]loss: 0.05971, 0.03982, 0.09953\n",
      "loss: 0.06105, 0.03830, 0.09934\n",
      " 53%|█████▎    | 159/299 [00:19<00:16,  8.35it/s]loss: 0.05051, 0.10768, 0.15819\n",
      " 54%|█████▎    | 160/299 [00:19<00:17,  7.97it/s]loss: 0.06830, 0.09383, 0.16212\n",
      " 54%|█████▍    | 161/299 [00:19<00:16,  8.28it/s]loss: 0.06290, 0.03832, 0.10122\n",
      " 54%|█████▍    | 162/299 [00:20<00:15,  8.61it/s]loss: 0.06233, 0.13573, 0.19806\n",
      "loss: 0.05875, 0.22172, 0.28046\n",
      " 55%|█████▍    | 164/299 [00:20<00:15,  8.58it/s]loss: 0.06865, 0.05118, 0.11982\n",
      " 55%|█████▌    | 165/299 [00:20<00:16,  8.10it/s]loss: 0.07167, 0.19223, 0.26390\n",
      " 56%|█████▌    | 166/299 [00:20<00:15,  8.36it/s]loss: 0.05662, 0.14950, 0.20612\n",
      " 56%|█████▌    | 167/299 [00:20<00:15,  8.41it/s]loss: 0.05447, 0.04975, 0.10422\n",
      "loss: 0.05745, 0.12180, 0.17924\n",
      " 57%|█████▋    | 169/299 [00:20<00:14,  8.78it/s]loss: 0.05232, 0.08920, 0.14152\n",
      " 57%|█████▋    | 170/299 [00:21<00:16,  7.68it/s]loss: 0.06338, 0.13570, 0.19908\n",
      " 57%|█████▋    | 171/299 [00:21<00:17,  7.35it/s]loss: 0.05355, 0.11377, 0.16732\n",
      " 58%|█████▊    | 172/299 [00:21<00:16,  7.78it/s]loss: 0.06517, 0.14646, 0.21163\n",
      " 58%|█████▊    | 173/299 [00:21<00:15,  7.92it/s]loss: 0.06338, 0.25388, 0.31726\n",
      "loss: 0.05809, 0.09246, 0.15055\n",
      " 59%|█████▊    | 175/299 [00:21<00:14,  8.59it/s]loss: 0.06253, 0.18483, 0.24736\n",
      "loss: 0.06702, 0.21587, 0.28289\n",
      " 59%|█████▉    | 177/299 [00:21<00:13,  8.93it/s]loss: 0.06346, 0.12750, 0.19096\n",
      " 60%|█████▉    | 178/299 [00:21<00:14,  8.18it/s]loss: 0.05834, 0.09138, 0.14971\n",
      "loss: 0.05193, 0.17480, 0.22673\n",
      " 60%|██████    | 180/299 [00:22<00:13,  8.87it/s]loss: 0.05595, 0.08583, 0.14178\n",
      " 61%|██████    | 181/299 [00:22<00:14,  8.30it/s]loss: 0.05958, 0.03776, 0.09734\n",
      " 61%|██████    | 182/299 [00:22<00:13,  8.55it/s]loss: 0.05528, 0.11263, 0.16791\n",
      " 61%|██████    | 183/299 [00:22<00:13,  8.69it/s]loss: 0.07227, 0.15809, 0.23035\n",
      " 62%|██████▏   | 184/299 [00:22<00:13,  8.68it/s]loss: 0.06623, 0.18992, 0.25615\n",
      " 62%|██████▏   | 185/299 [00:22<00:14,  7.96it/s]loss: 0.04723, 0.05091, 0.09814\n",
      " 62%|██████▏   | 186/299 [00:22<00:14,  7.69it/s]loss: 0.05525, 0.04395, 0.09920\n",
      "loss: 0.06329, 0.10794, 0.17123\n",
      " 63%|██████▎   | 188/299 [00:23<00:13,  8.21it/s]loss: 0.05828, 0.16295, 0.22123\n",
      " 63%|██████▎   | 189/299 [00:23<00:13,  7.93it/s]loss: 0.07511, 0.15599, 0.23110\n",
      " 64%|██████▎   | 190/299 [00:23<00:14,  7.27it/s]loss: 0.06618, 0.04996, 0.11613\n",
      "loss: 0.06926, 0.10823, 0.17748\n",
      " 64%|██████▍   | 192/299 [00:23<00:13,  7.67it/s]loss: 0.06322, 0.07853, 0.14175\n",
      "loss: 0.04778, 0.05210, 0.09988\n",
      " 65%|██████▍   | 194/299 [00:23<00:12,  8.48it/s]loss: 0.05185, 0.03779, 0.08963\n",
      "loss: 0.05066, 0.03383, 0.08450\n",
      " 66%|██████▌   | 196/299 [00:24<00:11,  8.72it/s]loss: 0.06045, 0.15408, 0.21453\n",
      " 66%|██████▌   | 197/299 [00:24<00:13,  7.47it/s]loss: 0.06331, 0.02864, 0.09195\n",
      " 66%|██████▌   | 198/299 [00:24<00:12,  7.77it/s]loss: 0.05786, 0.05370, 0.11156\n",
      "loss: 0.06287, 0.07222, 0.13509\n",
      " 67%|██████▋   | 200/299 [00:24<00:11,  8.34it/s]loss: 0.04867, 0.03459, 0.08327\n",
      " 67%|██████▋   | 201/299 [00:24<00:11,  8.76it/s]loss: 0.05879, 0.17588, 0.23467\n",
      " 68%|██████▊   | 202/299 [00:24<00:11,  8.22it/s]loss: 0.05301, 0.05454, 0.10755\n",
      " 68%|██████▊   | 203/299 [00:24<00:12,  7.86it/s]loss: 0.07021, 0.10117, 0.17137\n",
      " 68%|██████▊   | 204/299 [00:25<00:11,  8.03it/s]loss: 0.05375, 0.05276, 0.10651\n",
      "loss: 0.06847, 0.15412, 0.22260\n",
      " 69%|██████▉   | 206/299 [00:25<00:10,  8.73it/s]loss: 0.06486, 0.06855, 0.13341\n",
      " 69%|██████▉   | 207/299 [00:25<00:10,  9.02it/s]loss: 0.06797, 0.15528, 0.22325\n",
      " 70%|██████▉   | 208/299 [00:25<00:10,  8.58it/s]loss: 0.05642, 0.03322, 0.08964\n",
      " 70%|██████▉   | 209/299 [00:25<00:10,  8.71it/s]loss: 0.06392, 0.11976, 0.18368\n",
      " 70%|███████   | 210/299 [00:25<00:10,  8.64it/s]loss: 0.05880, 0.11599, 0.17479\n",
      "loss: 0.06420, 0.06719, 0.13139\n",
      " 71%|███████   | 212/299 [00:25<00:09,  8.76it/s]loss: 0.05324, 0.05345, 0.10669\n",
      "loss: 0.06050, 0.05683, 0.11732\n",
      " 72%|███████▏  | 214/299 [00:26<00:08,  9.51it/s]loss: 0.04943, 0.06934, 0.11876\n",
      " 72%|███████▏  | 215/299 [00:26<00:09,  8.87it/s]loss: 0.06117, 0.05459, 0.11575\n",
      " 72%|███████▏  | 216/299 [00:26<00:09,  8.52it/s]loss: 0.06850, 0.04299, 0.11148\n",
      "loss: 0.05119, 0.14760, 0.19879\n",
      " 73%|███████▎  | 218/299 [00:26<00:09,  8.67it/s]loss: 0.05519, 0.05810, 0.11328\n",
      " 73%|███████▎  | 219/299 [00:26<00:09,  8.66it/s]loss: 0.05162, 0.03737, 0.08899\n",
      " 74%|███████▎  | 220/299 [00:26<00:09,  8.60it/s]loss: 0.06288, 0.07991, 0.14280\n",
      " 74%|███████▍  | 221/299 [00:26<00:08,  8.94it/s]loss: 0.06425, 0.11703, 0.18129\n",
      " 74%|███████▍  | 222/299 [00:26<00:08,  8.60it/s]loss: 0.06611, 0.28712, 0.35324\n",
      " 75%|███████▍  | 223/299 [00:27<00:08,  8.80it/s]loss: 0.06106, 0.09668, 0.15774\n",
      " 75%|███████▍  | 224/299 [00:27<00:08,  8.62it/s]loss: 0.06425, 0.10290, 0.16715\n",
      " 75%|███████▌  | 225/299 [00:27<00:08,  8.98it/s]loss: 0.06457, 0.10178, 0.16635\n",
      " 76%|███████▌  | 226/299 [00:27<00:08,  8.33it/s]loss: 0.05991, 0.15064, 0.21055\n",
      " 76%|███████▌  | 227/299 [00:27<00:08,  8.50it/s]loss: 0.05490, 0.12794, 0.18284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 228/299 [00:27<00:08,  8.20it/s]loss: 0.06244, 0.12918, 0.19162\n",
      "loss: 0.05495, 0.03696, 0.09191\n",
      " 77%|███████▋  | 230/299 [00:27<00:08,  8.35it/s]loss: 0.05678, 0.02971, 0.08649\n",
      " 77%|███████▋  | 231/299 [00:28<00:07,  8.64it/s]loss: 0.05846, 0.20658, 0.26504\n",
      " 78%|███████▊  | 232/299 [00:28<00:08,  8.09it/s]loss: 0.05543, 0.09233, 0.14775\n",
      " 78%|███████▊  | 233/299 [00:28<00:07,  8.45it/s]loss: 0.06065, 0.03415, 0.09480\n",
      " 78%|███████▊  | 234/299 [00:28<00:08,  8.01it/s]loss: 0.05639, 0.09595, 0.15234\n",
      " 79%|███████▊  | 235/299 [00:28<00:07,  8.49it/s]loss: 0.05240, 0.06232, 0.11472\n",
      " 79%|███████▉  | 236/299 [00:28<00:07,  8.73it/s]loss: 0.05126, 0.01507, 0.06633\n",
      "loss: 0.06385, 0.04377, 0.10762\n",
      " 80%|███████▉  | 238/299 [00:28<00:06,  8.75it/s]loss: 0.06061, 0.15759, 0.21820\n",
      "loss: 0.05772, 0.11474, 0.17246\n",
      " 80%|████████  | 240/299 [00:29<00:06,  8.95it/s]loss: 0.05551, 0.14812, 0.20362\n",
      " 81%|████████  | 241/299 [00:29<00:06,  9.10it/s]loss: 0.06351, 0.09309, 0.15660\n",
      "loss: 0.05209, 0.12179, 0.17388\n",
      " 81%|████████▏ | 243/299 [00:29<00:05,  9.67it/s]loss: 0.05683, 0.02877, 0.08561\n",
      " 82%|████████▏ | 244/299 [00:29<00:06,  8.48it/s]loss: 0.06559, 0.03010, 0.09569\n",
      " 82%|████████▏ | 245/299 [00:29<00:06,  8.57it/s]loss: 0.06639, 0.14582, 0.21222\n",
      " 82%|████████▏ | 246/299 [00:29<00:06,  8.49it/s]loss: 0.06111, 0.11717, 0.17828\n",
      "loss: 0.05941, 0.02610, 0.08551\n",
      " 83%|████████▎ | 248/299 [00:29<00:05,  9.29it/s]loss: 0.06122, 0.14635, 0.20758\n",
      "loss: 0.05926, 0.09346, 0.15271\n",
      " 84%|████████▎ | 250/299 [00:30<00:05,  9.55it/s]loss: 0.06025, 0.04268, 0.10293\n",
      " 84%|████████▍ | 251/299 [00:30<00:05,  8.36it/s]loss: 0.06206, 0.19647, 0.25853\n",
      " 84%|████████▍ | 252/299 [00:30<00:06,  7.43it/s]loss: 0.06810, 0.21540, 0.28350\n",
      "loss: 0.05063, 0.07188, 0.12251\n",
      " 85%|████████▍ | 254/299 [00:30<00:05,  8.11it/s]loss: 0.06139, 0.05490, 0.11628\n",
      "loss: 0.05429, 0.06503, 0.11932\n",
      " 86%|████████▌ | 256/299 [00:30<00:04,  8.60it/s]loss: 0.05936, 0.06741, 0.12676\n",
      " 86%|████████▌ | 257/299 [00:30<00:04,  8.61it/s]loss: 0.06709, 0.14115, 0.20824\n",
      " 86%|████████▋ | 258/299 [00:31<00:04,  8.49it/s]loss: 0.05766, 0.08212, 0.13978\n",
      " 87%|████████▋ | 259/299 [00:31<00:04,  8.25it/s]loss: 0.06314, 0.12388, 0.18702\n",
      " 87%|████████▋ | 260/299 [00:31<00:04,  8.29it/s]loss: 0.06422, 0.09422, 0.15844\n",
      " 87%|████████▋ | 261/299 [00:31<00:04,  8.10it/s]loss: 0.05942, 0.08770, 0.14712\n",
      " 88%|████████▊ | 262/299 [00:31<00:04,  8.09it/s]loss: 0.06939, 0.16303, 0.23242\n",
      " 88%|████████▊ | 263/299 [00:31<00:04,  8.48it/s]loss: 0.05830, 0.08829, 0.14659\n",
      " 88%|████████▊ | 264/299 [00:31<00:04,  8.33it/s]loss: 0.05501, 0.03679, 0.09180\n",
      " 89%|████████▊ | 265/299 [00:31<00:04,  8.34it/s]loss: 0.04966, 0.05268, 0.10233\n",
      "loss: 0.05980, 0.13803, 0.19783\n",
      " 89%|████████▉ | 267/299 [00:32<00:03,  8.72it/s]loss: 0.05540, 0.05708, 0.11248\n",
      "loss: 0.05719, 0.05216, 0.10935\n",
      " 90%|████████▉ | 269/299 [00:32<00:03,  9.12it/s]loss: 0.05707, 0.08908, 0.14615\n",
      " 90%|█████████ | 270/299 [00:32<00:03,  9.09it/s]loss: 0.06061, 0.07955, 0.14016\n",
      " 91%|█████████ | 271/299 [00:32<00:03,  8.16it/s]loss: 0.07183, 0.28181, 0.35364\n",
      " 91%|█████████ | 272/299 [00:32<00:03,  7.90it/s]loss: 0.06606, 0.14951, 0.21557\n",
      " 91%|█████████▏| 273/299 [00:32<00:03,  8.32it/s]loss: 0.06102, 0.15326, 0.21429\n",
      " 92%|█████████▏| 274/299 [00:32<00:02,  8.57it/s]loss: 0.05431, 0.11239, 0.16670\n",
      " 92%|█████████▏| 275/299 [00:33<00:02,  8.85it/s]loss: 0.06771, 0.23105, 0.29876\n",
      " 92%|█████████▏| 276/299 [00:33<00:02,  8.97it/s]loss: 0.06817, 0.15853, 0.22670\n",
      " 93%|█████████▎| 277/299 [00:33<00:02,  8.90it/s]loss: 0.06011, 0.09536, 0.15547\n",
      " 93%|█████████▎| 278/299 [00:33<00:02,  8.74it/s]loss: 0.06451, 0.14112, 0.20563\n",
      " 93%|█████████▎| 279/299 [00:33<00:02,  8.46it/s]loss: 0.05265, 0.17504, 0.22769\n",
      " 94%|█████████▎| 280/299 [00:33<00:02,  8.28it/s]loss: 0.05218, 0.16529, 0.21748\n",
      " 94%|█████████▍| 281/299 [00:33<00:02,  8.07it/s]loss: 0.05421, 0.27630, 0.33051\n",
      " 94%|█████████▍| 282/299 [00:33<00:02,  8.02it/s]loss: 0.05873, 0.06557, 0.12430\n",
      " 95%|█████████▍| 283/299 [00:33<00:01,  8.00it/s]loss: 0.05515, 0.05304, 0.10820\n",
      " 95%|█████████▍| 284/299 [00:34<00:01,  8.01it/s]loss: 0.05818, 0.12881, 0.18699\n",
      "loss: 0.04761, 0.02724, 0.07485\n",
      " 96%|█████████▌| 286/299 [00:34<00:01,  8.93it/s]loss: 0.05371, 0.15626, 0.20996\n",
      "loss: 0.06177, 0.05699, 0.11877\n",
      " 96%|█████████▋| 288/299 [00:34<00:01,  9.84it/s]loss: 0.06052, 0.04649, 0.10701\n",
      "loss: 0.05536, 0.03250, 0.08786\n",
      " 97%|█████████▋| 290/299 [00:34<00:00, 10.64it/s]loss: 0.05147, 0.05315, 0.10462\n",
      "loss: 0.06010, 0.16053, 0.22062\n",
      " 98%|█████████▊| 292/299 [00:34<00:00, 11.22it/s]loss: 0.05038, 0.22329, 0.27368\n",
      "loss: 0.05979, 0.06746, 0.12724\n",
      " 98%|█████████▊| 294/299 [00:34<00:00, 11.71it/s]loss: 0.06543, 0.09132, 0.15675\n",
      "loss: 0.05089, 0.07304, 0.12393\n",
      " 99%|█████████▉| 296/299 [00:35<00:00, 12.10it/s]loss: 0.05706, 0.08707, 0.14412\n",
      "loss: 0.05050, 0.05050, 0.10100\n",
      "100%|█████████▉| 298/299 [00:35<00:00, 12.39it/s]loss: 0.04941, 0.04399, 0.09339\n",
      "100%|██████████| 299/299 [00:35<00:00,  8.46it/s]\n",
      "average loss : [0.05949629 0.11066426 0.17016055]\n",
      "average error: [ 0.15131992 19.36515131 18.27580832]\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "method = 'Adam'\n",
    "learning_rate = 0.0001\n",
    "max_epoch = 25\n",
    "\n",
    "staged_opt = StagedOptimizer(net, learning_rate)\n",
    "optimizer = staged_opt.get_optimizer()\n",
    "\n",
    "resume_training = True\n",
    "resume_path = './saved_models/temp/model_epoch25.pth.tar'\n",
    "if resume_training :\n",
    "    net, optimizer = resume_checkpoint(net, optimizer, resume_path)\n",
    "    test(net, test_data_loader,logger)\n",
    "    start_epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "staged_opt = StagedOptimizer(net, learning_rate)\n",
    "optimizer = staged_opt.update(24)\n",
    "save_path = './saved_models/temp/'\n",
    "save_checkpoint(net, optimizer, 24+1, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 32/3924 [00:14<29:58,  2.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-777e7fd18162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaged_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/gaze-on-objects/gazefollowing/training/train_gazenet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_dataloader, optimizer, epoch, logger)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_heatmap\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'face_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gaze_field'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eye_position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_heatmap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_heatmap\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_heatmap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "staged_opt = StagedOptimizer(net, learning_rate)\n",
    "\n",
    "for epoch in range(start_epoch, max_epoch):\n",
    "    \n",
    "    # Update optimizer\n",
    "    optimizer = staged_opt.update(epoch)\n",
    "\n",
    "    # Train model\n",
    "    train(net, train_data_loader, optimizer, epoch, logger)\n",
    "\n",
    "    # Save model and optimizer\n",
    "    if epoch > max_epoch-5:\n",
    "        save_path = './saved_models/temp/'\n",
    "        save_checkpoint(net, optimizer, epoch+1, save_path)\n",
    "    \n",
    "    # Evaluate model\n",
    "    test(net, test_data_loader, logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
