{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "from scipy import signal\n",
    "from utils import data_transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.gazenet import GazeNet\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from dataloader.gazenet import GooDataset, GazeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes2centers(normalized_boxes):\n",
    "    \n",
    "    center_x = (normalized_boxes[:,0] + normalized_boxes[:,2]) / 2\n",
    "    center_y = (normalized_boxes[:,1] + normalized_boxes[:,3]) / 2\n",
    "    center_x = np.expand_dims(center_x, axis=1)\n",
    "    center_y = np.expand_dims(center_y, axis=1)\n",
    "    normalized_centers = np.hstack((center_x, center_y))\n",
    "    \n",
    "    return normalized_centers\n",
    "\n",
    "def select_nearest_bbox(gazepoint, gt_bboxes, gt_labels):\n",
    "    '''\n",
    "    In: Accepts gazepoint (2,) and bboxes (n_boxes, 4), normalized from [0,1]\n",
    "    Out: Returns the bbox nearest to gazepoint.\n",
    "    '''\n",
    "    \n",
    "    centers = boxes2centers(gt_bboxes)\n",
    "    \n",
    "    diff = centers - gazepoint\n",
    "    l2dist = np.sqrt(diff[:,0]**2 + diff[:,1]**2)\n",
    "    min_idx = l2dist.argmin()\n",
    "    \n",
    "    \n",
    "    nearest_box = {\n",
    "        'box' : gt_bboxes[min_idx],\n",
    "        'label': gt_labels[min_idx],\n",
    "        'index' : min_idx\n",
    "    }\n",
    "    return nearest_box\n",
    "\n",
    "def calculate_metrics(npzfile, dataset):\n",
    "    predictions = np.load(npzfile)\n",
    "    \n",
    "    error = []\n",
    "    percent_dists=[0.01, 0.03, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "    PA_count = np.zeros((len(percent_dists)))\n",
    "    CPA_count = np.zeros((len(percent_dists)))\n",
    "    \n",
    "    for idx, f_point in tqdm(enumerate(predictions['gazepoints']), total=len(dataset)):\n",
    "        \n",
    "        data = dataset[idx]\n",
    "        \n",
    "        # Calculate L2, and use for pa/cpa\n",
    "        gt_point = data['gt_position'].numpy()\n",
    "        f_error = f_point - gt_point\n",
    "        f_dist = np.sqrt(f_error[0] ** 2 + f_error[1] ** 2)\n",
    "        error.append(f_dist)\n",
    "        \n",
    "        #Calc pa\n",
    "        PA_count[np.array(percent_dists) > f_dist] += 1   \n",
    "        \n",
    "        #Calc cpa\n",
    "        gt_bboxes, gt_labels, gaze_class = data['gt_bboxes'], data['gt_labels'], data['gaze_class']\n",
    "        #gt_bboxes = gt_bboxes / [640, 480, 640, 480]\n",
    "        selected_bbox = select_nearest_bbox(f_point, gt_bboxes, gt_labels)\n",
    "        if selected_bbox['label'] == gaze_class: \n",
    "            CPA_count[np.array(percent_dists) > f_dist] += 1   \n",
    "        \n",
    "        \n",
    "    mse = np.mean(np.array(error))\n",
    "    pa = PA_count / len(dataset)\n",
    "    cpa = CPA_count / len(dataset)\n",
    "    metrics = {\n",
    "        'mse' : mse,\n",
    "        'pa' : pa,\n",
    "        'cpa': cpa\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_result(image_path, eye, heatmap, gaze_point, gt_point, idx=0):\n",
    "    x1, y1 = eye\n",
    "    x2, y2 = gaze_point\n",
    "    x3, y3 = gt_point\n",
    "    im = cv2.imread(image_path)\n",
    "    image_height, image_width = im.shape[:2]\n",
    "    x1, y1 = image_width * x1, y1 * image_height\n",
    "    x2, y2 = image_width * x2, y2 * image_height\n",
    "    x3, y3 = image_width * x3, y3 * image_height\n",
    "    x1, y1, x2, y2, x3, y3 = map(int, [x1, y1, x2, y2, x3, y3])\n",
    "    cv2.circle(im, (x1, y1), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x2, y2), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x3, y3), 5, [255, 255, 255], -1)\n",
    "    cv2.line(im, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "    cv2.line(im, (x1, y1), (x3, y3), [0, 165, 255], 2)\n",
    "\n",
    "    # heatmap visualization\n",
    "    heatmap = ((heatmap - heatmap.min()) / (heatmap.max() - heatmap.min()) * 255).astype(np.uint8)\n",
    "    heatmap = np.stack([heatmap, heatmap, heatmap], axis=2)\n",
    "    heatmap = cv2.resize(heatmap, (image_width, image_height))\n",
    "\n",
    "    heatmap = (0.8 * heatmap.astype(np.float32) + 0.2 * im.astype(np.float32)).astype(np.uint8)\n",
    "    img = np.concatenate((im, heatmap), axis=1)\n",
    "    \n",
    "    save_dir = './sample_out/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    filename = 'out_%s.png' % str(idx)\n",
    "    save_path = save_dir + filename\n",
    "    print(save_path)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_save(net, test_data_loader, outfile='predictions.npz'):\n",
    "    net.eval()\n",
    "\n",
    "    all_heatmaps = []\n",
    "    all_gazepoints = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "            image, face_image, gaze_field, eye_position, gt_position, gt_heatmap = \\\n",
    "                data['image'], data['face_image'], data['gaze_field'], data['eye_position'], data['gt_position'], data['gt_heatmap']\n",
    "            image, face_image, gaze_field, eye_position, gt_position, gt_heatmap = \\\n",
    "                map(lambda x: Variable(x.cuda()), [image, face_image, gaze_field, eye_position, gt_position, gt_heatmap])\n",
    "\n",
    "            direction, predict_heatmap = net([image, face_image, gaze_field, eye_position])\n",
    "\n",
    "            final_output = predict_heatmap.cpu().data.numpy()\n",
    "            target = gt_position.cpu().data.numpy()\n",
    "            all_heatmaps.append(final_output)\n",
    "\n",
    "            for f_point, gt_point, eye_point in \\\n",
    "                zip(final_output, target, eye_position):\n",
    "                f_point = f_point.reshape([224 // 4, 224 // 4])\n",
    "\n",
    "                h_index, w_index = np.unravel_index(f_point.argmax(), f_point.shape)\n",
    "                f_point = np.array([w_index / 56., h_index / 56.])             \n",
    "                all_gazepoints.append(f_point)\n",
    "\n",
    "                f_error = f_point - gt_point\n",
    "                f_dist = np.sqrt(f_error[0] ** 2 + f_error[1] ** 2)\n",
    "\n",
    "    all_heatmaps = np.vstack(all_heatmaps).squeeze()\n",
    "    all_gazepoints = np.vstack(all_gazepoints)\n",
    "    np.savez(outfile, heatmaps=all_heatmaps, gazepoints=all_gazepoints)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar'\n",
      "=> Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar' (epoch 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/Documents/gaze-on-objects/gazefollowing/dataloader/gazenet.py:36: UserWarning: Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).\n",
      "  warnings.warn('Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 19200\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "net = GazeNet()\n",
    "net.cuda()\n",
    "\n",
    "resume_path = './saved_models/gazenet_goo/model_epoch25.pth.tar'\n",
    "net, optimizer, start_epoch = resume_checkpoint(net, None, resume_path)\n",
    "\n",
    "#Prepare dataloaders\n",
    "test_images_dir = '/hdd/HENRI/goosynth/test/'\n",
    "test_pickle_path = '/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\n",
    "batch_size = 16\n",
    "\n",
    "#For GOO\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test', use_bboxes=True)\n",
    "\n",
    "test_only = True\n",
    "if not test_only:\n",
    "    test_and_save(net, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19200/19200 [10:59<00:00, 29.12it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_path = 'predictions.npz'\n",
    "metrics = calculate_metrics(predictions_path, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.10772794595155237\n",
      "Percentage Distances:  [0.01, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
      "Proximate Accuracy: \t0.024\t0.147\t0.242\t0.318\t0.332\t0.334\t0.335\t0.336\t\n"
     ]
    }
   ],
   "source": [
    "PA_count = metrics['cpa']\n",
    "print('MSE: ', metrics['mse'])\n",
    "print(\"Percentage Distances: \", [0.01, 0.03, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30])\n",
    "print(\"Proximate Accuracy: \\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t\"%\n",
    "            (PA_count[0],\n",
    "            PA_count[1],\n",
    "            PA_count[2],\n",
    "            PA_count[3],\n",
    "            PA_count[4],\n",
    "            PA_count[5],\n",
    "            PA_count[6],\n",
    "            PA_count[7],\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_random(npzfile, dataset):\n",
    "    \n",
    "    # Load predictions from saved npz file\n",
    "    predictions = np.load(npzfile)\n",
    "    gazepoints = predictions['gazepoints']\n",
    "\n",
    "    # Get a random sample from dataset\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    data = dataset[idx]\n",
    "\n",
    "    # Load data from the sample\n",
    "    image, face_image, gaze_field, eye_position = data['image'], data['face_image'], data['gaze_field'], data['eye_position']\n",
    "    image, face_image, gaze_field, eye_position = map(lambda x: Variable(x.cuda(), volatile=True), [image, face_image, gaze_field, eye_position])\n",
    "    gt_position = data['gt_position']\n",
    "    image_path = data['image_path']\n",
    "    gt_bboxes = data['gt_bboxes']\n",
    "    gt_labels = data['gt_labels']\n",
    "    \n",
    "    # Draw gazepoints and gt\n",
    "    im = cv2.imread(image_path)\n",
    "    image_height, image_width = im.shape[:2]\n",
    "    x1, y1 = eye_position\n",
    "    x2, y2 = gt_position\n",
    "    x3, y3 = gazepoints[idx]\n",
    "    x1, y1 = image_width * x1, y1 * image_height\n",
    "    x2, y2 = image_width * x2, y2 * image_height\n",
    "    x3, y3 = image_width * x3, y3 * image_height\n",
    "    x1, y1, x2, y2, x3, y3 = map(int, [x1, y1, x2, y2, x3, y3])\n",
    "    cv2.circle(im, (x1, y1), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x2, y2), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x3, y3), 5, [255, 255, 255], -1)\n",
    "    cv2.line(im, (x1, y1), (x2, y2), [255, 0, 0], 2) \n",
    "    cv2.line(im, (x1, y1), (x3, y3), [0, 165, 255], 2) \n",
    "\n",
    "    # Select nearest bbox given the gazepoint\n",
    "    gazepoint = gazepoints[idx]\n",
    "    #gt_bboxes = gt_bboxes / [image_width, image_height, image_width, image_height]\n",
    "    bbox_data = select_nearest_bbox(gazepoint, gt_bboxes, gt_labels)\n",
    "    nearest_bbox = bbox_data['box']\n",
    "\n",
    "    # Scale to image size\n",
    "    nearest_bbox = nearest_bbox * [image_width, image_height, image_width, image_height]\n",
    "    nearest_bbox = nearest_bbox.astype(int)\n",
    "\n",
    "    # Draw bbox of prediction\n",
    "    cv2.rectangle(im, (nearest_bbox[0], nearest_bbox[1]), (nearest_bbox[2], nearest_bbox[3]), (0,165,255), 2)\n",
    "    \n",
    "    # Draw bbox of gt\n",
    "    gaze_idx = data['gaze_idx']\n",
    "    box = gt_bboxes[gaze_idx]\n",
    "    nearest_bbox = box * [image_width, image_height, image_width, image_height]\n",
    "    nearest_bbox = nearest_bbox.astype(int)\n",
    "    cv2.rectangle(im, (nearest_bbox[0], nearest_bbox[1]), (nearest_bbox[2], nearest_bbox[3]), (255,0,0), 2)\n",
    "\n",
    "    img = im\n",
    "    save_dir = './temp/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    filename = 'out_%s.png' % str(1)\n",
    "    save_path = save_dir + filename\n",
    "    cv2.imwrite(save_path, img)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/anaconda3/envs/gazefollow/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "demo_random('predictions.npz', val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar'\n",
      "=> Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar' (epoch 25)\n",
      "/home/eee198/Documents/gaze-on-objects/gazefollowing/dataloader/gazenet.py:36: UserWarning: Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).\n",
      "  warnings.warn('Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).')\n",
      "Number of Images: 19200\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "--test_dir='/hdd/HENRI/goosynth/test/'\\\n",
    "--test_annotation='/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\\\n",
    "--resume_path='./saved_models/gazenet_goo/model_epoch25.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
